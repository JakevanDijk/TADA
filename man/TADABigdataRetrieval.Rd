% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DataDiscoveryRetrieval.R
\name{TADABigdataRetrieval}
\alias{TADABigdataRetrieval}
\title{Large WQP data pulls using dataRetrieval}
\usage{
TADABigdataRetrieval(
  startDate = "null",
  endDate = "null",
  statecode = "null",
  characteristicName = "null",
  sampleMedia = "Water",
  siteType = "null",
  huc = "null",
  maxsitesquery = 20,
  applyautoclean = FALSE
)
}
\arguments{
\item{startDate}{Start Date YYYY-MM-DD format, for example, "1995-01-01"}

\item{endDate}{end date in YYYY-MM-DD format, for example, "2020-12-31"}

\item{statecode}{Character/character vector. State/territory abbreviations from FIPS codes consist of two letters}

\item{characteristicName}{Name of water quality parameter}

\item{sampleMedia}{Defaults to "Water". Refer to WQP domain tables for other options.}

\item{siteType}{Name of water body type (e.g., "Stream", "Lake, Reservoir, Impoundment")}

\item{huc}{A numeric code denoting a hydrologic unit. Example: "04030202". Different size hucs can be entered.}

\item{maxsitesquery}{Numeric. The maximum number of sites to query in each for-loop of the TADABigdataRetrieval function. This input is flexible because sites are often variable in their data richness. If several data rich sites are within the same download chunk, time outs and errors are more likely. Thus, the smaller the maxsitesquery (especially with very large datacalls), the lower the probability of overwhelming the WQP.}

\item{applyautoclean}{Defaults to FALSE. If TRUE, runs TADA's autoclean function on final combined dataset.}
}
\value{
TADA-compatible dataframe
}
\description{
This function does multiple synchronous data calls to the WQP
(waterqualitydata.us). It uses the WQP summary service to limit the amount
downloaded to only relevant data, and pulls back data from 100 stations at a
time and then joins the data back together and produces a single TADA
compatible dataframe as the output. For large data sets, that can save a lot
of time and ultimately reduce the complexity of subsequent data processing.
Using this function, you will be able to download all data available from all
sites in the contiguous United States that is available for the time period,
characteristicName, and siteType requested. Computer memory may limit the
size of datasets that your R console will be able to hold in one session.
Function requires a characteristicName, siteType, statecode, huc, or start/
end date input. The recommendation is to be as specific as you can with your
large data call. The function allows the user to run autoclean on the dataset,
but this is not the default as checking large dataframes for exact duplicate
rows can be time consuming and is better performed on its own once the query is
completed.
}
\details{
Some code for this function was adapted from this USGS Blog (Author: Aliesha Krall)
\href{https://waterdata.usgs.gov/blog/large_sample_pull/}{Large Sample Pull}

See ?autoclean documentation for more information on this optional input.
}
\examples{
\dontrun{
tada1 <- TADABigdataRetrieval(startDate = "2019-01-01", endDate = "2021-12-31", characteristicName = "Temperature, water", statecode = c("AK","AL"))
tada2 <- TADABigdataRetrieval(startDate = "2016-10-01",endDate = "2022-09-30", statecode = "UT")
tada3 = TADABigdataRetrieval(huc = "04030202", characteristicName = "Escherichia coli")
tada4 = TADABigdataRetrieval(huc = c("04030202","04030201"), characteristicName = "Temperature, water")
}

}
