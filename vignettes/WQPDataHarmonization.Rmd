---
title: "WQP Data Harmonization"
author: "Cristina Mullin"
date: "May 1, 2022"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{WQP Data Harmonization}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---
##Install dependency packages if needed
```{r}
list.of.packages <- c("plyr","dplyr","ggplot2","RColorBrewer","Rcpp","devtools",
          "data.table","grDevices","magrittr","stringr","testthat","usethis","utils","stats","rmarkdown","knitr","remotes")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
```

##Load dependency packages
```{r}
library(remotes)
library(dplyr)
library(ggplot2)
library(plyr)
library(RColorBrewer)
library(Rcpp)
library(data.table)
library(grDevices)
library(magrittr)
library(stringr)
library(testthat)
library(usethis)
library(utils)
library(stats)
library(rmarkdown)
library(knitr)
library(devtools)
```

#Load TADA and dataRetrieval
You can install and load the most recent versions from GitHub by running:
```{r}
remotes::install_github("USGS-R/dataRetrieval", dependencies=TRUE)
remotes::install_github("USEPA/TADA")
library(dataRetrieval)
library(TADA)
```

#Knit vignette
This code is used to build an HTML vignette
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Retrieve WQP data
WQP data is retrieved and processed for compatibility with TADA. This function, TADAdataRetrieval builds on the USGS dataRetrieval package functions. It joins three WQP profiles (i.e., the station, narrow, and phys/chem), changes all data in the Characteristic, Speciation, Fraction, and Unit fields to uppercase, removes true duplicates, removes data for all non-water media types, and cleans results with special characters.

This function uses the same inputs as the dataRetrieval `readWQPdata` function. `readWQPdata` does not restrict the characteristics pulled from WQP. You may specify the desired characteristics by using, for instance: 'characteristicName = "pH". 

More details about this function can be found in the function documentation by entering the following code into the console: ?TADAdataRetrieval

Here is more information on the dataRetrieval R Package:
[Introduction to the dataRetrieval package](https://cran.r-project.org/web/packages/dataRetrieval/vignettes/dataRetrieval.html)
[General Data Import from Water Quality Portal](https://rdrr.io/cran/dataRetrieval/man/readWQPdata.html)
[Water Quality Portal Web Services Guide](https://www.waterqualitydata.us/webservices_documentation/)
[dataRetrieval Tutorial](https://owi.usgs.gov/R/dataRetrieval.html

Water Quality Portal downloads have the same columns each time, but be aware that data are uploaded to the Water Quality Portal by individual organizations, which may or may not follow the same conventions. Data and metadata quality are not guaranteed! Make sure to carefully explore any data and make conservative quality assurance decisions where information is limited. 

In this vignette, we will walk through some of the things to look for when deciding to use different organizations data from the WQP.
```{r}
#You can edit this to define your own WQP query inputs below
TADAProfile <- TADAdataRetrieval(statecode = "24", 
                              characteristicName = c("Ammonia", "Nitrate", "Nitrogen"),
                              startDate = "01-01-2022")
```

## Depth unit conversions
Converts depth units to a consistent unit. 

**ActivityDepthHeightMeasure.MeasureValue** provides depth information. This is a crucial column for lake data but less often for river data.

Function checks dataset for depth profile data. Where depth profile columns are populated, the function appends 'Conversion Factor' columns and populates those columns based on the original unit (MeasureUnitCode columns) and the target unit, which is defined in the 'unit' argument. A 'Depth Target Unit' column is also appended, indicating the unit all selected depth data is converted to. When transform = FALSE, the output includes all 'Conversion Factor' columns and the 'Depth Target Unit' column. When transform = TRUE, the output includes converted depth data and the 'Depth Target Unit' column, which acts as a flag indicating which rows have been converted. Default is transform = TRUE.

The depth profile function can harmonize the depth units across all the following fields
(or only a specific one): "ActivityDepthHeightMeasure", "ActivityTopDepthHeightMeasure", 
"ActivityBottomDepthHeightMeasure", "ResultDepthHeightMeasure"). The default is all.

Allowable values for 'unit' are either 'm' (meter), 'ft' (feet), or 'in' (inch). 'unit' accepts only one allowable value as an input. Default is unit = "m".

See additional function documentation for additional function options by entering the following code in the console: 
?DepthProfileData

```{r}
#converts all depth profile data to meters
TADAProfileClean1 <- DepthProfileData(TADAProfile, unit = "m", transform = TRUE)

colnames(TADAProfileClean1)
```

# Result unit conversions
Converts all results to WQX target units. WQX target units are pulled from the MeasureUnit domain table: https://cdx2.epa.gov/wqx/download/DomainValues/MeasureUnit.CSV

See additional function documentation for additional function options by entering the following 
code in the console: 
?WQXTargetUnits

```{r}
#Converts all results to WQX target units
TADAProfileClean2 <- WQXTargetUnits(TADAProfileClean1, transform = TRUE)
```

##Continuous data
Checks for and removes aggregated continuous data, if present. 

The Water Quality Portal (WQP) is not designed to store high-frequency sensor data. However, sometimes data providers choose to aggregate their continuous data and submit it to WQP as one value. This type of data may not be suitable for integration with discrete water quality data for assessments. Therefore, this function uses metadata submitted by data providers to flags rows with aggregated continuous data. This is done by flagging results where the ResultDetectionConditionText = "Reported in Raw Data (attached)". When clean = TRUE, rows with aggregated continuous data are removed from the dataset and no column will be appended. Default is clean = TRUE.

See function documentation for additional function options by entering the following 
code in the console: 
?DepthProfileData
```{r}
TADAProfileClean3 <- AggregatedContinuousData(TADAProfileClean2, clean = TRUE)
```

## WQX QAQC Service Result Flags
Run the following result functions to address invalid method, fraction, speciation, and unit
metadata by characteristic. The default is Clean=TRUE, which will remove invalid results. 
You can change this to clean=FALSE to flag results, but not remove them. 

See documentation for more details:
?InvalidMethod
?InvalidSpeciation
?InvalidResultUnit
?InvalidFraction
```{r}
TADAProfileClean4 <- InvalidMethod(TADAProfileClean3, clean = TRUE)
TADAProfileClean5 <- InvalidFraction(TADAProfileClean4, clean = TRUE)
TADAProfileClean6 <- InvalidSpeciation(TADAProfileClean5, clean = TRUE)
TADAProfileClean7 <- InvalidResultUnit(TADAProfileClean6, clean = TRUE)
```

## WQX national upper and lower thresholds
Run the following code to flag or remove results that are above or below the national
upper and lower bound for each characteristic and unit combination. The default is 
clean=TRUE, but you can change this to only flag results if desired. Results will be 
flagged, but not removed, when clean=FALSE.
```{r}
TADAProfileClean8 <- AboveNationalWQXUpperThreshold(TADAProfileClean7, clean = TRUE)
TADAProfileClean9 <- BelowNationalWQXUpperThreshold(TADAProfileClean8, clean = TRUE)
```

# Potential duplicates
Sometimes multiple organizations submit the exact same data to Water Quality Portal (WQP), which can affect water quality analyses and assessments. This function checks for and identifies data that is identical in all fields excluding organization-specific and comment text fields. Each pair or group of potential duplicate rows is flagged with a unique ID. When clean = TRUE, the function retains the first occurrence of each potential duplicate in the dataset. Default is clean = TRUE.
```{r}
TADAProfileClean10 <- PotentialDuplicateRowID(TADAProfileClean9)
```

# Invalid coordinates
Function identifies and flags invalid coordinate data. When clean_outsideUSA = FALSE and clean_imprecise = FALSE, a column will be appended titled "TADA.InvalidCoordinates" with the following flags (if relevant to dataset). If the latitude is less than zero, the row will be flagged with "LAT_OutsideUSA". If the longitude is greater than zero AND less than 145, the row will be flagged as "LONG_OutsideUSA". If the latitude or longitude contains the string, "999", the row will be flagged as invalid. Finally, precision can be measured by the number of decimal places in the latitude and longitude provided. If either does not have any numbers to the right of the decimal point, the row will be flagged as "Imprecise".

```{r}
TADAProfileClean11 <- InvalidCoordinates(TADAProfileClean10, clean_outsideUSA = FALSE, clean_imprecise = FALSE)
```

# QAPPapproved
Check data for an approved QAPP

This function checks to see if there is any information in the column "QAPPApprovedIndicator". Some organizations submit data for this field to indicate if the data produced has an approved Quality Assurance Project Plan (QAPP) or not. In this field, Y indicates yes, N indicates no. 

This function has two default inputs: clean = TRUE and cleanNA = FALSE. These defaults remove rows of data where the QAPPApprovedIndicator equals "N". Users could alternatively remove both N's and NA's using the inputs clean = TRUE and cleanNA = TRUE. If both clean = FALSE and cleanNA = FALSE, the function will not do anything.
```{r}
TADAProfileClean12 <- QAPPapproved(TADAProfileClean11, clean = TRUE, cleanNA = FALSE)
```

# QAPPDocAvailable
This function checks data submitted under the "ProjectFileUrl" column to determine if a QAPP document is available to review. When clean = FALSE,
a column will be appended to flag results that do have an associated
QAPP document URL provided. When clean = TRUE, rows that do not
have an associated QAPP document are removed from the dataset and no column
will be appended. This function should only be used to remove data if an
accompanying QAPP document is required to use data in assessments.
```{r}
TADAProfileClean13 <- QAPPDocAvailable(TADAProfileClean12, clean = FALSE)
```

## Filter data by field
In this section a TADA user will want to review the unique values in specific fields and may choose to remove data with particular values. 

To start, review the list of fields and the number of unique values in each field.
```{r, echo=FALSE}
FilterFields(TADAProfileClean13)
```

Next, choose a field from the list to see the unique values in that field, as well as the number of times each value appears in the dataset. We'll start with ActivityTypeCode.

Here is a list of other fields to review:
1. **ResultCommentText** often has details relating to additional QA.
2. **MeasureQualifierCode** Contains information about data flags
3. Other codes may designate suspect data or other flags which may be described in detail in **ResultLaboratoryCommentText** or another column
```{r, echo=FALSE}
FilterFieldReview("ActivityTypeCode", TADAProfileClean13)
```

The ActivityTypeCode field has four unique values -- "Sample-Routine", "Quality Control Sample-Field Replicate", "Field Msr/Obs", and "Quality Control Sample-Field Blank." In this example we want to remove quality control values in the ActivityTypeCode field, therefore, we'll specify that we want to remove the "Quality Control Sample-Field Replicate" and "Quality Control Sample-Field Blank" values in the ActivityTypeCode field.
```{r}
TADAProfileClean14 <- dplyr::filter(TADAProfileClean13, !(ActivityTypeCode %in% c("Quality Control Sample-Field Replicate", "Quality Control Sample-Field Blank")))
```

We've completed our review of the ActivityTypeCode field. 

Let's move on to a different field and see if there are any values that we want to remove -- we'll look at the values in the ResultStatusIdentifier field.
```{r, echo=FALSE}
FilterFieldReview("ActivityMediaSubdivisionName", TADAProfileClean14)
```

The ActivityMediaSubdivisionName field has two unique values, "Surface Water" and "Groundwater." In this example we want to remove the "Groundwater" values. 
```{r}
TADAProfileClean15 <- dplyr::filter(TADAProfileClean14, !(ActivityMediaSubdivisionName %in% "Groundwater"))
```

## Filter data by field, subset by parameter
In this section a TADA user will want to select a parameter, review the unique values associated with that parameter in specific fields, and choose to remove particular values. 

To start, review the list of parameters in the dataset. (The list is sorted from highest to lowest counts. Only the first few rows are displayed to save space on the page) 
```{r, echo=FALSE}
FilterParList(TADAProfileClean15)
```

Next, select a parameter. Let's explore the fields associated with Nitrogen:
```{r, echo=FALSE}
FilterParFields(TADAProfileClean15, "NITROGEN")
```

Selecting a parameter generates the list below, which is subset by the selected parameter, of fields and the number of unique values in each field.

Then choose a field from the list. In this example we'll remove certain values from the HydrologicEvent field.
```{r, echo=FALSE}
FilterParFieldReview("HydrologicEvent", TADAProfileClean15, "NITROGEN")
```

The HydrologicEvent field has three unique values. In this example we want to remove samples collected during "Storm" events. Therefore, we'll specify that we want to remove rows where the CharacteristicName is "NITROGEN" and the HydrologicEvent field is "Storm." 

```{r}
TADAProfileClean16 <- dplyr::filter(TADAProfileClean15, !(CharacteristicName %in% "NITROGEN" & HydrologicEvent %in% "Storm"))
```

## Transform Characteristic, Speciation, and Unit values to TADA Standards
The HarmonizeRefTable function generates a harmonization reference table that is specific to the input dataset. Users can review how their input data relates to standard TADA values for CharacteristicName, ResultSampleFractionText, MethodSpecicationName, and ResultMeasure.MeasureUnitCode and they can optionally edit the reference file to meet their needs. The download argument can be used to save the harmonization file to your 
current working directory when download = TRUE, the default is download = FALSE. 

The HarmonizeData function then compares the input dataset to the TADA Harmonization Reference Table. The purpose of the function is to make similar data consistent and therefore easier to compare and analyze. Optional outputs include: 1) the dataset with Harmonization columns appended, 2) the datset with CharacteristicName, ResultSampleFractionText, MethodSpecificationName, and ResultMeasure.MeasureUnitCode converted to TADA standards or 3) the four fields converted with most Harmonization Reference Table columns appended. Default is transform = TRUE and flag = TRUE.

Here are some examples of how the HarmonizeData function can be used:
1. **ResultSampleFractionText** specifies forms of constituents. In some cases, a single **CharacteristicName** will have both "Total" and "Dissolved" forms specified, which should not be combined. In these cases, each CharacteristicName and ResultSampleFractionText combination is given a different identier. This identifer can be used later on to identify comparable data groups for calculating statistics and creating figures for each combination.
2. Some variables have different names but represent the same constituent (e.g., "Total Kjeldahl nitrogen (Organic N & NH3)" and "Kjeldahl nitrogen"). The HarmonizeData function gives a consistent name (and identifier) to synonyms.

```{r}
UniqueHarmonizationRef <- HarmonizationRefTable(TADAProfileClean16, download = FALSE)
TADAProfileClean17 <- HarmonizeData(TADAProfileClean16, ref = UniqueHarmonizationRef, transform = TRUE, flag = TRUE)
```
